#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¿»è¨³ã‚­ãƒ¼ã®ä½¿ç”¨çŠ¶æ³ã‚’è©³ç´°ã«åˆ†æã—ã€æ–°ã—ã„ja.jsonã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
import re
import os
from pathlib import Path
from typing import Dict, List, Set, Tuple

def load_translation_file(file_path: str) -> Dict:
    """ç¿»è¨³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def extract_translation_usage_per_file(file_path: str) -> Tuple[Set[str], Set[str]]:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®ç¿»è¨³ä½¿ç”¨çŠ¶æ³ã‚’æŠ½å‡º
    Returns: (namespaces, translation_keys)
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        namespaces = set()
        translation_keys = set()
        
        # useTranslations()ã®ä½¿ç”¨ç®‡æ‰€ã‚’æ¤œç´¢
        translations_matches = re.findall(r'useTranslations\(["\']([^"\']+)["\']\)', content)
        
        # getTranslations()ã®ä½¿ç”¨ç®‡æ‰€ã‚‚æ¤œç´¢
        get_translations_matches = re.findall(r'getTranslations\([^}]+namespace:\s*["\']([^"\']+)["\']', content)
        
        # namespaceã‚’è¨˜éŒ²
        for namespace in translations_matches + get_translations_matches:
            namespaces.add(namespace)
        
        # t()ã®ä½¿ç”¨ç®‡æ‰€ã‚’æ¤œç´¢ï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
        t_patterns = [
            r't\(\s*["\']([^"\']+)["\']\s*\)',  # t("key")
            r't\(\s*["`]([^"`]+)["`]\s*\)',    # t(`key`)
        ]
        
        t_keys = set()
        for pattern in t_patterns:
            matches = re.findall(pattern, content)
            t_keys.update(matches)
        
        # namespaceã¨çµ„ã¿åˆã‚ã›ãŸå®Œå…¨ãªã‚­ãƒ¼ã‚’ç”Ÿæˆ
        for namespace in namespaces:
            for t_key in t_keys:
                if '.' in t_key:
                    # ã™ã§ã«å®Œå…¨ãªãƒ‘ã‚¹
                    translation_keys.add(t_key)
                else:
                    # namespaceã¨çµ„ã¿åˆã‚ã›
                    full_key = f"{namespace}.{t_key}"
                    translation_keys.add(full_key)
        
        # namespaceãŒãªã„å ´åˆã®t()ã‚­ãƒ¼ã‚‚è¿½åŠ 
        if not namespaces:
            for t_key in t_keys:
                translation_keys.add(t_key)
                
        return namespaces, translation_keys
        
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return set(), set()

def analyze_all_files(src_dir: str) -> Dict[str, Dict[str, Set[str]]]:
    """å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¿»è¨³ä½¿ç”¨çŠ¶æ³ã‚’åˆ†æ"""
    file_analysis = {}
    
    for root, _, files in os.walk(src_dir):
        for file in files:
            if file.endswith(('.tsx', '.ts', '.js', '.jsx')):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, src_dir)
                
                namespaces, translation_keys = extract_translation_usage_per_file(file_path)
                
                if namespaces or translation_keys:
                    file_analysis[relative_path] = {
                        'namespaces': namespaces,
                        'translation_keys': translation_keys
                    }
    
    return file_analysis

def collect_used_keys(file_analysis: Dict) -> Set[str]:
    """ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ç¿»è¨³ã‚­ãƒ¼ã‚’å…¨ã¦åé›†"""
    used_keys = set()
    
    for file_info in file_analysis.values():
        used_keys.update(file_info['translation_keys'])
        # namespaceã‚‚ã‚­ãƒ¼ã¨ã—ã¦è¿½åŠ 
        used_keys.update(file_info['namespaces'])
    
    return used_keys

def create_minimal_translations(original: Dict, used_keys: Set[str]) -> Dict:
    """ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã®ã¿ã‚’å«ã‚€æœ€å°é™ã®ç¿»è¨³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    def get_nested_value(obj: Dict, key_path: str):
        """ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å€¤ã‚’å–å¾—"""
        keys = key_path.split('.')
        current = obj
        
        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None
        return current
    
    def set_nested_value(obj: Dict, key_path: str, value):
        """ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å€¤ã‚’è¨­å®š"""
        keys = key_path.split('.')
        current = obj
        
        for key in keys[:-1]:
            if key not in current:
                current[key] = {}
            current = current[key]
        
        current[keys[-1]] = value
    
    minimal = {}
    
    # ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã‚’ã‚½ãƒ¼ãƒˆã—ã¦å‡¦ç†
    for key in sorted(used_keys):
        value = get_nested_value(original, key)
        if value is not None:
            set_nested_value(minimal, key, value)
    
    return minimal

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_root = "/Users/yamashitanatsuki/Documents/WorkingSpace/startup-nextjs"
    ja_file = os.path.join(project_root, "messages", "ja.json")
    src_dir = os.path.join(project_root, "src")
    
    print("ğŸ” è©³ç´°ãªç¿»è¨³ã‚­ãƒ¼åˆ†æã‚’å®Ÿè¡Œä¸­...")
    
    # ç¾åœ¨ã®ja.jsonã‚’èª­ã¿è¾¼ã¿
    original_translations = load_translation_file(ja_file)
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¿»è¨³ä½¿ç”¨çŠ¶æ³ã‚’åˆ†æ
    file_analysis = analyze_all_files(src_dir)
    
    print(f"ğŸ“ åˆ†æã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_analysis)}")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®è©³ç´°è¡¨ç¤º
    print("\nğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã®ç¿»è¨³ä½¿ç”¨çŠ¶æ³:")
    for file_path, info in file_analysis.items():
        if info['namespaces'] or info['translation_keys']:
            print(f"  {file_path}:")
            if info['namespaces']:
                print(f"    Namespaces: {', '.join(sorted(info['namespaces']))}")
            if info['translation_keys']:
                print(f"    Keys: {len(info['translation_keys'])}å€‹")
    
    # ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã‚’åé›†
    used_keys = collect_used_keys(file_analysis)
    
    print(f"\nâœ… å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ç¿»è¨³ã‚­ãƒ¼: {len(used_keys)}å€‹")
    print(f"ğŸ“Š å…ƒã®ja.jsonã®ã‚­ãƒ¼æ•°: {len(get_all_keys(original_translations))}å€‹")
    
    # æœ€å°é™ã®ç¿»è¨³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    minimal_translations = create_minimal_translations(original_translations, used_keys)
    
    # æ–°ã—ã„ja.jsonãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    output_file = os.path.join(project_root, "messages", "ja_minimal.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(minimal_translations, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æœ€å°åŒ–ã•ã‚ŒãŸja.jsonã‚’ä½œæˆ: {output_file}")
    print(f"ğŸ“‰ å‰Šæ¸›ã•ã‚ŒãŸã‚­ãƒ¼æ•°: {len(get_all_keys(original_translations)) - len(get_all_keys(minimal_translations))}å€‹")

def get_all_keys(obj: Dict, prefix: str = "") -> Set[str]:
    """ãƒã‚¹ãƒˆã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ã‚­ãƒ¼ã‚’å–å¾—"""
    keys = set()
    for key, value in obj.items():
        if prefix:
            full_key = f"{prefix}.{key}"
        else:
            full_key = key
            
        keys.add(full_key)
        
        if isinstance(value, dict):
            keys.update(get_all_keys(value, full_key))
            
    return keys

if __name__ == "__main__":
    main()
