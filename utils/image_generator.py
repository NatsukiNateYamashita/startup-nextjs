#!/usr/bin/env python3
"""
ç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

æ³¨æ„: ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ç”»åƒç”ŸæˆAPIï¼ˆDALL-Eã€Stable Diffusionã€Unsplashç­‰ï¼‰ã®å®Ÿè£…ä¾‹ã§ã™ã€‚
å®Ÿéš›ã®ä½¿ç”¨ã«ã¯é©åˆ‡ãªç”»åƒç”ŸæˆAPIã‚µãƒ¼ãƒ“ã‚¹ã¨ã®é€£æºãŒå¿…è¦ã§ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python image_generator.py --article-id "006"
    python image_generator.py --article-id "006" --service "unsplash"
"""

import json
import argparse
import requests
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import io

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import (
    BLOG_IMAGES_DIR,
    BLOG_POSTS_DIR,
    get_anthropic_client
)

# Unsplash APIè¨­å®š
UNSPLASH_ACCESS_KEY = "FC3pujO19B3C3e3RMxdV874S3Iz6IOjdnYbb3FvZoo0"
UNSPLASH_SECRET_KEY = "MbqDJbWyD2X_SWHkQukMPdBH4be7AfytJsLe2GkyDTI"

class UnsplashImageGenerator:
    def __init__(self):
        self.access_key = UNSPLASH_ACCESS_KEY
        self.base_url = "https://api.unsplash.com"
    
    def search_and_download_image(self, keyword, filename, width=1200, height=800):
        """Unsplashã‹ã‚‰ç”»åƒã‚’æ¤œç´¢ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            search_url = f"{self.base_url}/photos/random"
            params = {
                "query": keyword,
                "orientation": "landscape",
                "w": width,
                "h": height,
                "content_filter": "high"
            }
            
            headers = {
                "Authorization": f"Client-ID {self.access_key}"
            }
            
            print(f"ğŸ” '{keyword}'ã§ç”»åƒã‚’æ¤œç´¢ä¸­...")
            response = requests.get(search_url, params=params, headers=headers)
            
            if response.status_code == 200:
                data = response.json()
                image_url = data['urls']['regular']
                alt_description = data.get('alt_description', keyword)
                photographer = data['user']['name']
                
                print(f"ğŸ“¸ è¦‹ã¤ã‘ãŸç”»åƒ: {alt_description} by {photographer}")
                
                # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                img_response = requests.get(image_url)
                if img_response.status_code == 200:
                    with open(filename, 'wb') as f:
                        f.write(img_response.content)
                    
                    print(f"âœ… ç”»åƒä¿å­˜å®Œäº†: {filename}")
                    return {
                        "success": True,
                        "alt_description": alt_description,
                        "photographer": photographer,
                        "unsplash_url": data['links']['html']
                    }
                else:
                    print(f"âŒ ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {img_response.status_code}")
                    return {"success": False, "error": "ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—"}
            else:
                print(f"âŒ APIå‘¼ã³å‡ºã—å¤±æ•—: {response.status_code}")
                print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {response.text}")
                return {"success": False, "error": f"API error: {response.status_code}"}
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            return {"success": False, "error": str(e)}

def load_captions_data(article_id):
    """captions.jsonã‚’èª­ã¿è¾¼ã¿"""
    images_dir = BLOG_IMAGES_DIR / article_id
    captions_path = images_dir / "captions.json"
    
    if not captions_path.exists():
        raise FileNotFoundError(f"âŒ captions.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {captions_path}")
    
    try:
        with open(captions_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        raise ValueError(f"âŒ captions.jsonã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def load_english_content(article_id):
    """è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆen.md, meta.jsonï¼‰ã‚’èª­ã¿è¾¼ã¿"""
    posts_dir = BLOG_POSTS_DIR / article_id
    en_md_path = posts_dir / "en.md"
    meta_json_path = posts_dir / "meta.json"
    
    content_data = {
        "title": "",
        "content": "",
        "tags": []
    }
    
    # en.mdã‚’èª­ã¿è¾¼ã¿
    if not en_md_path.exists():
        raise FileNotFoundError(f"âŒ en.mdãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {en_md_path}")
    
    try:
        with open(en_md_path, "r", encoding="utf-8") as f:
            en_content = f.read()
            
            # frontmatterã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
            if en_content.startswith('---'):
                end_pos = en_content.find('---', 3)
                if end_pos != -1:
                    frontmatter = en_content[3:end_pos]
                    for line in frontmatter.split('\n'):
                        if line.startswith('title:'):
                            content_data["title"] = line.split(':', 1)[1].strip().strip('"\'')
                    
                    # æœ¬æ–‡éƒ¨åˆ†ã‚’å–å¾—
                    content_data["content"] = en_content[end_pos + 3:].strip()
    except Exception as e:
        raise IOError(f"âŒ en.mdèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # meta.jsonã‹ã‚‰ã‚¿ã‚°ã‚’èª­ã¿è¾¼ã¿
    if not meta_json_path.exists():
        raise FileNotFoundError(f"âŒ meta.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {meta_json_path}")
    
    try:
        with open(meta_json_path, "r", encoding="utf-8") as f:
            meta_data = json.load(f)
            if "tags" in meta_data and "en" in meta_data["tags"]:
                content_data["tags"] = meta_data["tags"]["en"]
    except Exception as e:
        raise ValueError(f"âŒ meta.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    return content_data

def create_search_query(english_content, image_key, caption_data):
    """è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æƒ…å ±ã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ä½œæˆ"""
    query_parts = []
    
    # è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰é‡è¦ãªéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆçŸ­ç¸®ï¼‰
    title = english_content.get("title", "")
    if title:
        # ã‚¿ã‚¤ãƒˆãƒ«ã‚’é©åº¦ãªé•·ã•ã«åˆ¶é™ï¼ˆæœ€åˆã®5-6èªç¨‹åº¦ï¼‰
        title_words = title.split()[:6]
        title_short = " ".join(title_words)
        query_parts.append(title_short)
    
    # caption.enã®alt textã‚’è¿½åŠ 
    en_alt = caption_data.get("alt", {}).get("en", "")
    if en_alt:
        query_parts.append(en_alt)
    
    # caption.enã®captionã‚’è¿½åŠ ï¼ˆalt textã¨ç•°ãªã‚‹å ´åˆï¼‰
    en_caption = caption_data.get("caption", {}).get("en", "")
    if en_caption and en_caption != en_alt:
        query_parts.append(en_caption)
    
    # meta.jsonã®enã‚¿ã‚°ã‚’è¿½åŠ ï¼ˆæœ€åˆã®2-3å€‹ã ã‘ï¼‰
    tags = english_content.get("tags", [])
    if tags:
        selected_tags = tags[:3]  # æœ€åˆã®3å€‹ã®ã‚¿ã‚°ã®ã¿
        query_parts.extend(selected_tags)
    
    # ã‚¯ã‚¨ãƒªã‚’çµåˆã—ã¦é©åº¦ãªé•·ã•ã«åˆ¶é™
    full_query = " ".join(query_parts)
    
    # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆUnsplashã®æ¤œç´¢åŠ¹ç‡ã‚’è€ƒæ…®ï¼‰
    words = full_query.split()
    if len(words) > 8:  # 8èªä»¥å†…ã«åˆ¶é™
        full_query = " ".join(words[:8])
    
    return full_query.strip()

def generate_image_prompt(image_key, caption_data):
    """ç”»åƒç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
    ja_alt = caption_data.get("alt", {}).get("ja", "")
    ja_caption = caption_data.get("caption", {}).get("ja", "")
    en_alt = caption_data.get("alt", {}).get("en", "")
    
    # è‹±èªã®èª¬æ˜ã‚’å„ªå…ˆã—ã€æ—¥æœ¬èªã‚‚å‚è€ƒã«ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    prompt_parts = []
    
    if en_alt:
        prompt_parts.append(en_alt)
    elif ja_alt:
        prompt_parts.append(f"Japanese education related: {ja_alt}")
    
    if ja_caption and ja_caption != ja_alt:
        prompt_parts.append(f"Context: {ja_caption}")
    
    # ç”»åƒã®ç¨®é¡ã«å¿œã˜ãŸã‚¹ã‚¿ã‚¤ãƒ«æŒ‡å®š
    if "hero" in image_key.lower():
        style = "professional, modern, clean design, technology theme, educational"
    else:
        style = "clean, educational, illustrative, modern design"
    
    prompt = " | ".join(prompt_parts)
    full_prompt = f"{prompt} | Style: {style} | High quality, suitable for blog article"
    
    return full_prompt

def generate_with_unsplash(article_id, captions_data):
    """Unsplash APIã‚’ä½¿ã£ã¦ç”»åƒã‚’ç”Ÿæˆï¼ˆè‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ï¼‰"""
    generator = UnsplashImageGenerator()
    images_dir = BLOG_IMAGES_DIR / article_id
    images_dir.mkdir(parents=True, exist_ok=True)
    
    # è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã¿
    english_content = load_english_content(article_id)
    
    generated_images = []
    updated_captions = {}
    
    for image_key, caption_data in captions_data.items():
        if not image_key.endswith(('.jpg', '.jpeg', '.png')):
            continue
            
        print(f"ğŸ–¼ï¸  å‡¦ç†ä¸­: {image_key}")
        
        # è‹±èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
        search_query = create_search_query(english_content, image_key, caption_data)
        print(f"   æ¤œç´¢ã‚¯ã‚¨ãƒª: {search_query}")
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        image_file = images_dir / image_key
        
        # Unsplashã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        result = generator.search_and_download_image(search_query, str(image_file))
        
        if result["success"]:
            generated_images.append(image_file)
            
            # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æ›´æ–°ï¼ˆå†™çœŸå®¶ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆè¿½åŠ ï¼‰
            updated_captions[image_key] = {
                **caption_data,
                "photographer": result["photographer"],
                "unsplash_url": result["unsplash_url"],
                "source": "Unsplash",
                "search_query": search_query  # ä½¿ç”¨ã—ãŸã‚¯ã‚¨ãƒªã‚‚ä¿å­˜
            }
            print(f"âœ… {image_key} ç”Ÿæˆå®Œäº†ï¼ by {result['photographer']}")
        else:
            print(f"âŒ {image_key} ç”Ÿæˆå¤±æ•—: {result['error']}")
            raise RuntimeError(f"ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {image_key} - {result['error']}")
    
    # æ›´æ–°ã•ã‚ŒãŸã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ä¿å­˜
    captions_file = images_dir / "captions.json"
    with open(captions_file, "w", encoding="utf-8") as f:
        json.dump(updated_captions, f, ensure_ascii=False, indent=2)
    
    return generated_images

def generate_images(article_id, service="unsplash"):
    """ç”»åƒç”Ÿæˆã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print(f"ğŸ¨ è¨˜äº‹ {article_id} ã®ç”»åƒç”Ÿæˆã‚’é–‹å§‹...")
    
    # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
    captions_data = load_captions_data(article_id)
    
    # ã‚µãƒ¼ãƒ“ã‚¹ã«å¿œã˜ã¦ç”»åƒç”Ÿæˆ
    if service == "unsplash":
        return generate_with_unsplash(article_id, captions_data)
    else:
        raise ValueError(f"âŒ æœªå¯¾å¿œã®ã‚µãƒ¼ãƒ“ã‚¹: {service}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument("--article-id", required=True, help="è¨˜äº‹ID")
    parser.add_argument("--service", default="unsplash", choices=["unsplash"], help="ç”»åƒç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹")
    
    args = parser.parse_args()
    
    result = generate_images(args.article_id, args.service)
    print(f"âœ… ç”Ÿæˆå®Œäº†: {len(result)} æšã®ç”»åƒ")
  