#!/usr/bin/env python3
"""
è¨˜äº‹ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
    python translator.py --article-id "006"
    python translator.py --article-id "006" --languages en zh-CN
"""

import json
import argparse
from pathlib import Path

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import (
    get_anthropic_client,
    BLOG_POSTS_DIR,
    PROMPTS_DIR,
    SUPPORTED_LANGUAGES
)

def load_translation_prompt():
    """ç¿»è¨³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    prompt_file = PROMPTS_DIR / "translation.md"
    
    if not prompt_file.exists():
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_file}")
        return None
        
    with open(prompt_file, "r", encoding="utf-8") as f:
        return f.read()

def load_source_article(article_id):
    """æ—¥æœ¬èªã®å…ƒè¨˜äº‹ã‚’èª­ã¿è¾¼ã¿"""
    article_dir = BLOG_POSTS_DIR / article_id
    ja_md_path = article_dir / "ja.md"
    
    if not ja_md_path.exists():
        print(f"âŒ æ—¥æœ¬èªè¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ja_md_path}")
        print("ã¾ãš article_generator.py ã§è¨˜äº‹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        return None
    
    with open(ja_md_path, "r", encoding="utf-8") as f:
        return f.read()

def translate_article(source_content, target_language):
    """è¨˜äº‹ã‚’æŒ‡å®šã—ãŸè¨€èªã«ç¿»è¨³"""
    print(f"ğŸŒ {SUPPORTED_LANGUAGES.get(target_language, target_language)} ã¸ã®ç¿»è¨³ä¸­...")
    
    # Anthropicã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    client = get_anthropic_client()
    if not client:
        return None
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
    prompt_template = load_translation_prompt()
    if not prompt_template:
        return None
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æƒ…å ±ã‚’æŒ¿å…¥
    prompt = prompt_template.replace("{source_content}", source_content)
    prompt = prompt.replace("{target_language}", SUPPORTED_LANGUAGES.get(target_language, target_language))
    
    try:
        # APIå‘¼ã³å‡ºã—
        response = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            # model="claude-sonnet-4-20250514",
            max_tokens=8000,
            temperature=0.3,  # ç¿»è¨³ã§ã¯ä½ã‚ã®æ¸©åº¦ã‚’ä½¿ç”¨
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        
        content = response.content[0].text
        
        # Markdownéƒ¨åˆ†ã‚’æŠ½å‡º
        md_start = content.find("---")
        if md_start != -1:
            return content[md_start:].strip()
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å…¨ä½“ã‚’è¿”ã™
            return content.strip()
        
    except Exception as e:
        print(f"âŒ ç¿»è¨³APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def save_translated_article(article_id, language, translated_content):
    """ç¿»è¨³ã•ã‚ŒãŸè¨˜äº‹ã‚’ä¿å­˜"""
    article_dir = BLOG_POSTS_DIR / article_id
    translated_file = article_dir / f"{language}.md"
    
    with open(translated_file, "w", encoding="utf-8") as f:
        f.write(translated_content)
    
    print(f"âœ… {SUPPORTED_LANGUAGES.get(language, language)} è¨˜äº‹ã‚’ä¿å­˜: {translated_file}")
    return translated_file

def update_meta_tags(article_id, translations):
    """meta.jsonã®ã‚¿ã‚°æƒ…å ±ã‚’ç¿»è¨³ã§æ›´æ–°"""
    article_dir = BLOG_POSTS_DIR / article_id
    meta_json_path = article_dir / "meta.json"
    
    if not meta_json_path.exists():
        print("âš ï¸  meta.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¿ã‚°ã®ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
    
    try:
        with open(meta_json_path, "r", encoding="utf-8") as f:
            meta_data = json.load(f)
        
        # ã‚¿ã‚°ã®å½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆé…åˆ—å½¢å¼ã‹å¤šè¨€èªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã‹ï¼‰
        if "tags" in meta_data:
            if isinstance(meta_data["tags"], list):
                # æ–°å½¢å¼ï¼šé…åˆ—ã®å ´åˆã¯å¤šè¨€èªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
                base_tags = meta_data["tags"]
                meta_data["tags"] = {
                    "ja": base_tags,
                    "en": base_tags,  # ä¸€æ—¦åŒã˜ã‚¿ã‚°ã‚’è¨­å®šï¼ˆå°†æ¥çš„ã«ã¯ç¿»è¨³å¯èƒ½ï¼‰
                    "zh-CN": base_tags,
                    "zh-TW": base_tags
                }
            elif isinstance(meta_data["tags"], dict):
                # æ—§å½¢å¼ï¼šå¤šè¨€èªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                base_tags = meta_data["tags"].get("ja", [])
                for lang in translations.keys():
                    if lang not in meta_data["tags"]:
                        meta_data["tags"][lang] = base_tags
        
        with open(meta_json_path, "w", encoding="utf-8") as f:
            json.dump(meta_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°: {meta_json_path}")
        
    except (json.JSONDecodeError, Exception) as e:
        print(f"âš ï¸  ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã«å¤±æ•—: {e}")

def update_captions(article_id, translations):
    """captions.jsonã®å„è¨€èªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°"""
    from config import BLOG_IMAGES_DIR
    
    images_dir = BLOG_IMAGES_DIR / article_id
    captions_path = images_dir / "captions.json"
    
    if not captions_path.exists():
        print("âš ï¸  captions.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ç¿»è¨³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
    
    try:
        with open(captions_path, "r", encoding="utf-8") as f:
            captions_data = json.load(f)
        
        # ç°¡æ˜“å®Ÿè£…: æ—¢å­˜ã®æ—¥æœ¬èªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ä»–è¨€èªã«ã‚³ãƒ”ãƒ¼
        # æœ¬æ ¼çš„ãªå®Ÿè£…ã§ã¯å„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚‚ç¿»è¨³APIã‚’ä½¿ç”¨
        for image_key, image_data in captions_data.items():
            if "alt" in image_data and "caption" in image_data:
                ja_alt = image_data["alt"].get("ja", "")
                ja_caption = image_data["caption"].get("ja", "")
                
                for lang in translations.keys():
                    if lang not in image_data["alt"]:
                        image_data["alt"][lang] = ja_alt  # ä¸€æ—¦åŒã˜å†…å®¹ã‚’è¨­å®š
                    if lang not in image_data["caption"]:
                        image_data["caption"][lang] = ja_caption
        
        with open(captions_path, "w", encoding="utf-8") as f:
            json.dump(captions_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°: {captions_path}")
        
    except (json.JSONDecodeError, Exception) as e:
        print(f"âš ï¸  ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®æ›´æ–°ã«å¤±æ•—: {e}")

def check_article_exists(article_id):
    """è¨˜äº‹ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
    article_dir = BLOG_POSTS_DIR / article_id
    ja_md_path = article_dir / "ja.md"
    
    if not article_dir.exists():
        print(f"âŒ è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {article_dir}")
        return False
    
    if not ja_md_path.exists():
        print(f"âŒ æ—¥æœ¬èªè¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {ja_md_path}")
        return False
    
    return True

def main():
    parser = argparse.ArgumentParser(description="è¨˜äº‹ã‚’å¤šè¨€èªã«ç¿»è¨³ã—ã¾ã™")
    parser.add_argument("--article-id", required=True, help="ç¿»è¨³ã™ã‚‹è¨˜äº‹ã®ID")
    parser.add_argument(
        "--languages", 
        nargs="+",
        default=["en", "zh-CN", "zh-TW"],
        choices=list(SUPPORTED_LANGUAGES.keys()),
        help="ç¿»è¨³å…ˆè¨€èªï¼ˆè¤‡æ•°æŒ‡å®šå¯èƒ½ï¼‰"
    )
    parser.add_argument("--force", action="store_true", help="æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã")
    
    args = parser.parse_args()
    
    print("ğŸŒ è¨˜äº‹ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"ğŸ“ è¨˜äº‹ID: {args.article_id}")
    print(f"ğŸŒ ç¿»è¨³è¨€èª: {', '.join([SUPPORTED_LANGUAGES.get(lang, lang) for lang in args.languages])}")
    print("-" * 50)
    
    # è¨˜äº‹ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not check_article_exists(args.article_id):
        return
    
    # æ—¥æœ¬èªè¨˜äº‹ã‚’èª­ã¿è¾¼ã¿
    source_content = load_source_article(args.article_id)
    if not source_content:
        return
    
    translations = {}
    
    # å„è¨€èªã«ç¿»è¨³
    for language in args.languages:
        if language == "ja":
            print("âš ï¸  æ—¥æœ¬èªã¯å…ƒè¨˜äº‹ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            continue
        
        # ç¿»è¨³å®Ÿè¡Œ
        translated_content = translate_article(source_content, language)
        
        if translated_content:
            # ç¿»è¨³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
            saved_file = save_translated_article(args.article_id, language, translated_content)
            translations[language] = saved_file
        else:
            print(f"âŒ {SUPPORTED_LANGUAGES.get(language, language)} ã¸ã®ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°
    if translations:
        update_meta_tags(args.article_id, translations)
        update_captions(args.article_id, translations)
        
        print(f"\nâœ… ç¿»è¨³ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"ğŸ“ è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {BLOG_POSTS_DIR / args.article_id}")
        print(f"ğŸ—‚ï¸  ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(translations)}å€‹")
        
        for lang, file_path in translations.items():
            print(f"   â€¢ {SUPPORTED_LANGUAGES.get(lang, lang)}: {file_path.name}")
        
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. image_generator.py ã§ç”»åƒç”Ÿæˆ")
        print("2. validator.py ã§ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆãƒã‚§ãƒƒã‚¯")
    else:
        print("âŒ ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
