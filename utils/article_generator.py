#!/usr/bin/env python3
"""
è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå·¦å³å¯¾è¨³å¯¾å¿œç‰ˆï¼‰

æ–°æ©Ÿèƒ½:
- sentenceã‚¿ã‚°è‡ªå‹•æŒ¿å…¥
- å¤šè¨€èªé–“ã®sentenceã‚¿ã‚°IDæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- å·¦å³å¯¾è¨³ãƒšãƒ¼ã‚¸å¯¾å¿œè¨˜äº‹ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
    python article_generator.py --idea-id "010"
    python article_generator.py --custom-title "ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¤ãƒˆãƒ«"
"""

import json
import re
import argparse
from datetime import datetime
from pathlib import Path

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from config import (
    get_anthropic_client,
    IDEAS_FILE,
    PROMPTS_DIR,
    BLOG_POSTS_DIR,
    BLOG_IMAGES_DIR,
    BLOG_INDEX_FILE,  # è¿½åŠ 
    DEFAULT_AUTHOR_ID,
    ensure_directories
)

def load_prompt_template():
    """è¨˜äº‹ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ï¼ˆå·¦å³å¯¾è¨³å¯¾å¿œç‰ˆï¼‰"""
    # æ–°ã—ã„sentenceã‚¿ã‚°å¯¾å¿œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
    prompt_file = PROMPTS_DIR / "article_generation_with_sentence_tags.md"
    
    if not prompt_file.exists():
        print(f"âš ï¸  å·¦å³å¯¾è¨³å¯¾å¿œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_file}")
        print("âš ï¸  å¾“æ¥ç‰ˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
        prompt_file = PROMPTS_DIR / "article_generation.md"
    
    if not prompt_file.exists():
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {prompt_file}")
        return None
        
    with open(prompt_file, "r", encoding="utf-8") as f:
        return f.read()

def validate_sentence_tags(content: str):
    """sentenceã‚¿ã‚°ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    tags = re.findall(r'<!--\s*s(\d+)\s*-->', content)
    tag_numbers = [int(tag) for tag in tags]
    
    return {
        "has_tags": len(tag_numbers) > 0,
        "total_tags": len(tag_numbers),
        "tag_numbers": tag_numbers,
        "is_sequential": tag_numbers == list(range(1, len(tag_numbers) + 1)),
        "duplicates": len(tag_numbers) != len(set(tag_numbers))
    }

def inject_sentence_tags(content: str) -> str:
    """ç”Ÿæˆã•ã‚ŒãŸãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã«sentenceã‚¿ã‚°ã‚’è‡ªå‹•æŒ¿å…¥"""
    if '<!-- s1 -->' in content:
        print("âœ… sentenceã‚¿ã‚°ãŒæ—¢ã«å«ã¾ã‚Œã¦ã„ã¾ã™")
        return content
    
    print("ğŸ”§ sentenceã‚¿ã‚°ã‚’è‡ªå‹•æŒ¿å…¥ä¸­...")
    
    lines = content.split('\n')
    result = []
    tag_counter = 1
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # ç©ºè¡Œã¯ãã®ã¾ã¾è¿½åŠ 
        if not stripped:
            result.append(line)
            continue
        
        # frontmatterã¯ä¿æŒ
        if stripped == '---' and i < 5:
            result.append(line)
            continue
        
        # sentenceã‚¿ã‚°ã‚’è¿½åŠ ã™ã‚‹æ¡ä»¶ã‚’ãƒã‚§ãƒƒã‚¯
        should_add_tag = False
        
        # H1, H2, H3è¦‹å‡ºã—
        if re.match(r'^#{1,3}\s+', stripped):
            should_add_tag = True
        
        # æ®µè½ï¼ˆæ–‡å­—ã§å§‹ã¾ã‚‹è¡Œã€ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚„ç‰¹æ®Šè¨˜å·ä»¥å¤–ï¼‰
        elif re.match(r'^[^\-\*\`\#\|\<\>\[]', stripped) and not stripped.startswith('```'):
            # å‰ã®è¡ŒãŒç©ºè¡Œã¾ãŸã¯è¦‹å‡ºã—ã®å ´åˆã®ã¿æ®µè½é–‹å§‹ã¨ã¿ãªã™
            if i == 0 or not lines[i-1].strip() or re.match(r'^#{1,3}\s+', lines[i-1].strip()):
                should_add_tag = True
        
        # ãƒªã‚¹ãƒˆé …ç›®ã®æœ€åˆ
        elif re.match(r'^[\-\*]\s+\*\*', stripped):  # "- **é …ç›®**:" å½¢å¼
            should_add_tag = True
        
        # ç•ªå·ãƒªã‚¹ãƒˆã®æœ€åˆ
        elif re.match(r'^\d+\.\s+\*\*', stripped):  # "1. **é …ç›®**:" å½¢å¼
            should_add_tag = True
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å‰
        elif stripped.startswith('```') and not any('```' in prev_line for prev_line in lines[max(0, i-3):i]):
            should_add_tag = True
        
        if should_add_tag:
            result.append(f"<!-- s{tag_counter} -->")
            result.append(line)
            tag_counter += 1
        else:
            result.append(line)
    
    final_content = '\n'.join(result)
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    validation = validate_sentence_tags(final_content)
    print(f"ğŸ“Š sentenceã‚¿ã‚°çµ±è¨ˆ: {validation['total_tags']}å€‹ã®ã‚¿ã‚°")
    if not validation['is_sequential']:
        print("âš ï¸  è­¦å‘Š: sentenceã‚¿ã‚°ã®ç•ªå·ãŒé€£ç¶šã—ã¦ã„ã¾ã›ã‚“")
    
    return final_content

def load_ideas():
    """ä¿å­˜ã•ã‚ŒãŸã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã‚’èª­ã¿è¾¼ã¿"""
    if not IDEAS_FILE.exists():
        print(f"âŒ ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {IDEAS_FILE}")
        print("ã¾ãš idea_generator.py ã‚’å®Ÿè¡Œã—ã¦ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        return None
        
    with open(IDEAS_FILE, "r", encoding="utf-8") as f:
        try:
            return json.load(f)
        except json.JSONDecodeError:
            print("âŒ ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒä¸æ­£ã§ã™")
            return None

def find_idea_by_id(ideas_data, idea_id):
    """IDã§ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã‚’æ¤œç´¢"""
    if not ideas_data or "ideas" not in ideas_data:
        return None
        
    for idea in ideas_data["ideas"]:
        if idea.get("id") == idea_id:
            return idea
    return None

def list_available_ideas():
    """åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ä¸€è¦§ã‚’è¡¨ç¤º"""
    ideas_data = load_ideas()
    if not ideas_data:
        return
        
    print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¤ãƒ‡ã‚£ã‚¢:")
    print("-" * 50)
    
    for idea in ideas_data["ideas"]:
        print(f"ID: {idea.get('id', 'N/A')} - {idea.get('title', {}).get('ja', 'N/A')}")
        print(f"   ã‚«ãƒ†ã‚´ãƒª: {idea.get('category', 'N/A')}")
        print()

def create_article_directory(article_id):
    """è¨˜äº‹ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
    article_dir = BLOG_POSTS_DIR / article_id
    images_dir = BLOG_IMAGES_DIR / article_id
    
    article_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)
    
    return article_dir, images_dir

def generate_article_content(client, idea):
    """Claude APIã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ"""
    print(f"ğŸ¤– è¨˜äº‹ç”Ÿæˆä¸­: {idea.get('title', {}).get('ja', '')}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
    prompt_template = load_prompt_template()
    if not prompt_template:
        return None
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢æƒ…å ±ã‚’æŒ¿å…¥
    current_date = datetime.now().isoformat()
    
    prompt = prompt_template
    prompt = prompt.replace("{title}", idea.get('title', {}).get('ja', ''))
    prompt = prompt.replace("{category}", idea.get('category', ''))
    prompt = prompt.replace("{target_audience}", idea.get('target_audience', ''))
    prompt = prompt.replace("{key_points}", '\n'.join([f"- {point}" for point in idea.get('key_points', [])]))
    prompt = prompt.replace("{word_count}", str(idea.get('estimated_word_count', 3000)))
    prompt = prompt.replace("{article_id}", idea.get('id', ''))
    prompt = prompt.replace("{current_date}", current_date)
    
    try:
        # APIå‘¼ã³å‡ºã—
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=16000,
            temperature=0.7,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        
        content = response.content[0].text
        
        print(f"âœ… Claude API ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—å®Œäº† ({len(content)} æ–‡å­—)")
        
        return parse_generated_content(content, idea)
        
    except Exception as e:
        print(f"âŒ APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def parse_generated_content(content, idea):
    """ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è§£æã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«åˆ†é›¢"""
    
    result = {
        "markdown": "",
        "meta_json": {},
        "captions_json": {}
    }
    
    try:
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³éƒ¨åˆ†ã‚’æŠ½å‡º
        markdown_match = re.search(r'```markdown\s*\n(.*?)(?=\n```json|\n```\s*$|$)', content, re.DOTALL)
        if markdown_match:
            result["markdown"] = markdown_match.group(1).strip()
            
            # sentenceã‚¿ã‚°ã®è‡ªå‹•æŒ¿å…¥
            result["markdown"] = inject_sentence_tags(result["markdown"])
        
        # meta.jsonéƒ¨åˆ†ã‚’æŠ½å‡º
        meta_match = re.search(r'```json\s*\n(\{.*?"authorId".*?\})\s*\n```', content, re.DOTALL)
        if meta_match:
            try:
                result["meta_json"] = json.loads(meta_match.group(1))
                print("âœ… meta.jsonã‚’æ­£å¸¸ã«ãƒ‘ãƒ¼ã‚¹ã—ã¾ã—ãŸ")
            except json.JSONDecodeError:
                print("âš ï¸  meta.json ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # captions.jsonéƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆæˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
        # 1. ã¾ãšã™ã¹ã¦ã®JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’è¦‹ã¤ã‘ã‚‹
        all_json_blocks = re.findall(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
        print(f"ğŸ” è¦‹ã¤ã‹ã£ãŸJSONãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(all_json_blocks)}")
        
        captions_found = False
        for i, json_block in enumerate(all_json_blocks):
            print(f"ğŸ” JSONãƒ–ãƒ­ãƒƒã‚¯ {i+1} ã®åˆ†æä¸­...")
            
            # meta.jsonã¯æ—¢ã«å‡¦ç†ã—ãŸã®ã§ã‚¹ã‚­ãƒƒãƒ—
            if '"authorId"' in json_block:
                print(f"   â†’ meta.jsonãƒ–ãƒ­ãƒƒã‚¯ã€ã‚¹ã‚­ãƒƒãƒ—")
                continue
            
            # captions.jsonã®ç‰¹å¾´ã‚’æ¢ã™
            has_image_keys = any(ext in json_block for ext in ['.jpg', '.jpeg', '.png', '.webp'])
            has_lang_keys = any(lang in json_block for lang in ['"ja":', '"en":', '"zh-CN":', '"zh-TW":'])
            has_alt_or_caption = any(key in json_block for key in ['"alt":', '"caption":'])
            
            print(f"   â†’ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­: {has_image_keys}")
            print(f"   â†’ è¨€èªã‚­ãƒ¼: {has_lang_keys}")
            print(f"   â†’ alt/captionã‚­ãƒ¼: {has_alt_or_caption}")
            
            # captions.jsonã®å¯èƒ½æ€§ãŒé«˜ã„å ´åˆ
            if has_image_keys or (has_lang_keys and has_alt_or_caption):
                print(f"   â†’ captions.jsonã®å¯èƒ½æ€§ãŒé«˜ã„ã€ãƒ‘ãƒ¼ã‚¹è©¦è¡Œ")
                try:
                    # JSONé–‹å§‹ã® { ã‹ã‚‰æœ€å¾Œã® } ã¾ã§ã‚’æŠ½å‡º
                    json_start = json_block.find('{')
                    if json_start >= 0:
                        json_end = json_block.rfind('}')
                        if json_end > json_start:
                            clean_json = json_block[json_start:json_end+1]
                            result["captions_json"] = json.loads(clean_json)
                            print("âœ… captions.jsonã‚’æ­£å¸¸ã«ãƒ‘ãƒ¼ã‚¹ã—ã¾ã—ãŸ")
                            captions_found = True
                            break
                except json.JSONDecodeError as e:
                    print(f"   â†’ ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            else:
                print(f"   â†’ captions.jsonã®ç‰¹å¾´ãªã—ã€ã‚¹ã‚­ãƒƒãƒ—")
        
        # captions.jsonãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not captions_found:
            print("âš ï¸  captions.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½œæˆã—ã¾ã™")
            result["captions_json"] = create_default_captions(idea)
        
        return result
        
    except Exception as e:
        print(f"âŒ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None

def save_article_files(article_data, article_id):
    """è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
    article_dir = BLOG_POSTS_DIR / article_id
    images_dir = BLOG_IMAGES_DIR / article_id
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    article_dir.mkdir(parents=True, exist_ok=True)
    images_dir.mkdir(parents=True, exist_ok=True)
    
    # æ—¥æœ¬èªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
    if article_data["markdown"]:
        ja_file = article_dir / "ja.md"
        with open(ja_file, "w", encoding="utf-8") as f:
            f.write(article_data["markdown"])
        print(f"âœ… æ—¥æœ¬èªè¨˜äº‹ã‚’ä¿å­˜: {ja_file}")
        
        # sentenceã‚¿ã‚°ã®çµ±è¨ˆè¡¨ç¤º
        validation = validate_sentence_tags(article_data["markdown"])
        print(f"ğŸ“Š sentenceã‚¿ã‚°çµ±è¨ˆ: {validation['total_tags']}å€‹")
    
    # meta.jsonãƒ•ã‚¡ã‚¤ãƒ«
    if article_data["meta_json"]:
        meta_file = article_dir / "meta.json"
        with open(meta_file, "w", encoding="utf-8") as f:
            json.dump(article_data["meta_json"], f, ensure_ascii=False, indent=2)
        print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {meta_file}")
    
    # captions.jsonãƒ•ã‚¡ã‚¤ãƒ«
    if article_data["captions_json"]:
        captions_file = images_dir / "captions.json"
        with open(captions_file, "w", encoding="utf-8") as f:
            json.dump(article_data["captions_json"], f, ensure_ascii=False, indent=2)
        print(f"âœ… ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ä¿å­˜: {captions_file}")
    
    return article_dir
    
    if not result["meta_json"]:
        result["meta_json"] = create_default_meta(idea)
    
    if not result["captions_json"]:
        result["captions_json"] = create_default_captions(idea)
    
    return result

def create_default_meta(idea):
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    return {
        "authorId": DEFAULT_AUTHOR_ID,
        "tags": {
            "ja": idea.get('seo_keywords', [])[:3],
            "en": idea.get('seo_keywords', [])[:3],
            "zh-CN": idea.get('seo_keywords', [])[:3],
            "zh-TW": idea.get('seo_keywords', [])[:3]
        },
        "publishDate": datetime.now().isoformat(),
        "heroImage": f"/images/blog/{idea.get('id', '')}/hero.jpg",
        "featured": False,
        "relatedPosts": []
    }

def create_default_captions(idea):
    """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    return {
        "hero.jpg": {
            "alt": {
                "ja": f"{idea.get('title', {}).get('ja', '')}ã®ã‚¤ãƒ¡ãƒ¼ã‚¸",
                "en": f"Image for {idea.get('title', {}).get('en', '')}"
            },
            "caption": {
                "ja": "è¨˜äº‹ã®ãƒ’ãƒ¼ãƒ­ãƒ¼ç”»åƒ",
                "en": "Hero image for the article"
            }
        }
    }

def rebuild_blog_index():
    """æ—¢å­˜ã®å…¨è¨˜äº‹ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ãƒ–ãƒ­ã‚°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†æ§‹ç¯‰"""
    print("ğŸ“š ãƒ–ãƒ­ã‚°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ä¸­...")
    
    # è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
    posts = []
    all_tags = set()
    
    if not BLOG_POSTS_DIR.exists():
        print(f"âš ï¸  è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {BLOG_POSTS_DIR}")
        # ç©ºã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        index_data = {"posts": [], "tags": [], "lastUpdated": datetime.now().isoformat(), "totalPosts": 0}
    else:
        # å„è¨˜äº‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³
        for article_dir in BLOG_POSTS_DIR.iterdir():
            if not article_dir.is_dir():
                continue
                
            article_id = article_dir.name
            meta_file = article_dir / "meta.json"
            
            if not meta_file.exists():
                raise FileNotFoundError(f"âŒ meta.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {meta_file}")
            
            try:
                with open(meta_file, "r", encoding="utf-8") as f:
                    meta_data = json.load(f)
            except json.JSONDecodeError as e:
                raise ValueError(f"âŒ meta.jsonã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ ({meta_file}): {e}")
            
            # è¨˜äº‹æƒ…å ±ã‚’ä½œæˆ
            post_info = {
                "id": article_id,
                "slug": article_id,
                "publishDate": meta_data.get("publishDate", datetime.now().isoformat()),
                "featured": meta_data.get("featured", False),
                "authorId": meta_data.get("authorId", DEFAULT_AUTHOR_ID)
            }
            posts.append(post_info)
            
            # ã‚¿ã‚°æƒ…å ±ã‚’åé›†
            if "tags" in meta_data:
                for lang_tags in meta_data["tags"].values():
                    if isinstance(lang_tags, list):
                        all_tags.update(lang_tags)
            
            print(f"ğŸ“„ è¨˜äº‹ã‚’ã‚¹ã‚­ãƒ£ãƒ³: {article_id}")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        index_data = {
            "posts": sorted(posts, key=lambda x: x["publishDate"], reverse=True),  # æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
            "tags": sorted(list(all_tags)),
            "lastUpdated": datetime.now().isoformat(),
            "totalPosts": len(posts)
        }
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open(BLOG_INDEX_FILE, "w", encoding="utf-8") as f:
        json.dump(index_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ãƒ–ãƒ­ã‚°ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰: {BLOG_INDEX_FILE}")
    print(f"ğŸ“Š ç·è¨˜äº‹æ•°: {len(posts)}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå·¦å³å¯¾è¨³å¯¾å¿œç‰ˆï¼‰")
    parser.add_argument("--idea-id", help="ä½¿ç”¨ã™ã‚‹ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã®ID")
    parser.add_argument("--custom-title", help="ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¤ãƒˆãƒ«")
    parser.add_argument("--list", action="store_true", help="åˆ©ç”¨å¯èƒ½ãªã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ä¸€è¦§ã‚’è¡¨ç¤º")
    
    args = parser.parse_args()
    
    print("ğŸš€ è¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå·¦å³å¯¾è¨³å¯¾å¿œç‰ˆï¼‰")
    print("=" * 50)
    
    if args.list:
        list_available_ideas()
        return
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
    ensure_directories()
    
    # Claude APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = get_anthropic_client()
    if not client:
        return
    
    # ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã®æº–å‚™
    if args.custom_title:
        idea = {
            "id": f"custom-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "title": {"ja": args.custom_title},
            "category": "ã‚«ã‚¹ã‚¿ãƒ ",
            "target_audience": "ä¸€èˆ¬",
            "key_points": ["ã‚«ã‚¹ã‚¿ãƒ è¨˜äº‹"],
            "estimated_word_count": 3000
        }
    elif args.idea_id:
        ideas_data = load_ideas()
        if not ideas_data:
            return
        
        idea = find_idea_by_id(ideas_data, args.idea_id)
        if not idea:
            print(f"âŒ ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ID '{args.idea_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            list_available_ideas()
            return
    else:
        print("âŒ --idea-id ã¾ãŸã¯ --custom-title ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        list_available_ideas()
        return
    
    # è¨˜äº‹ç”Ÿæˆ
    article_data = generate_article_content(client, idea)
    if not article_data:
        print("âŒ è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    article_dir = save_article_files(article_data, idea["id"])
    
    print(f"\nğŸ‰ è¨˜äº‹ç”Ÿæˆå®Œäº†!")
    print(f"ğŸ“ ä¿å­˜å…ˆ: {article_dir}")
    print(f"ï¿½ å·¦å³å¯¾è¨³ãƒšãƒ¼ã‚¸ã§ç¢ºèª:")
    print(f"   http://localhost:3001/ja/compare/{idea['id']}?left=ja&right=en")
    print(f"\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"   1. translator.py ã§å¤šè¨€èªåŒ–")
    print(f"   2. image_generator.py ã§ç”»åƒç”Ÿæˆ")

if __name__ == "__main__":
    main()
